{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "openai_api_key=os.getenv(\"OPEN_API_KEY\")\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat', # 或者使用 'deepseek-reasoner' (对应 DeepSeek-R1)\n",
    "    openai_api_key=openai_api_key,\n",
    "    base_url='https://api.deepseek.com', # 必须修改此项，指向 DeepSeek 的服务器\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "llm=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of allowed moves of arbitrary length. We show that the diameter of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. We then study the mixing behaviour of heat-bath random walks on these graphs. We also state explicit conditions on the set of moves so that the heat-bath random walk, a generalization of the Glauber dynamics, is an expander in fixed dimension.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv=ArxivAPIWrapper()\n",
    "docs=arxiv.run(\"1605.08386\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2025-09-22\\nTitle: Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking\\nAuthors: Zihan Su, Xuerui Qiu, Hongbin Xu, Tangyu Jiang, Junhao Zhuang, Chun Yuan, Ming Li, Shengfeng He, Fei Richard Yu\\nSummary: The explosive growth of generative video models has amplified the demand for reliable copyright preservation of AI-generated content. Despite its popularity in image synthesis, invisible generative watermarking remains largely underexplored in video generation. To address this gap, we propose Safe-Sora, the first framework to embed graphical watermarks directly into the video generation process. Motivated by the observation that watermarking performance is closely tied to the visual similarity between the watermark and cover content, we introduce a hierarchical coarse-to-fine adaptive matching mechanism. Specifically, the watermark image is divided into patches, each assigned to the most visually similar video frame, and further localized to the optimal spatial region for seamless embedding. To enable spatiotemporal fusion of watermark patches across video frames, we develop a 3D wavelet transform-enhanced Mamba architecture with a novel spatiotemporal local scanning strategy, effectively modeling long-range dependencies during watermark embedding and retrieval. To the best of our knowledge, this is the first attempt to apply state space models to watermarking, opening new avenues for efficient and robust watermark protection. Extensive experiments demonstrate that Safe-Sora achieves state-of-the-art performance in terms of video quality, watermark fidelity, and robustness, which is largely attributed to our proposals. Code is publicly available at https://github.com/Sugewud/Safe-Sora\\n\\nPublished: 2024-03-02\\nTitle: Sora OpenAI's Prelude: Social Media Perspectives on Sora OpenAI and the Future of AI Video Generation\\nAuthors: Reza Hadi Mogavi, Derrick Wang, Joseph Tu, Hilda Hadan, Sabrina A. Sgandurra, Pan Hui, Lennart E. Nacke\\nSummary: The rapid advancement of Generative AI (Gen-AI) is transforming Human-Computer Interaction (HCI), with significant implications across various sectors. This study investigates the public's perception of Sora OpenAI, a pioneering Gen-AI video generation tool, via social media discussions on Reddit before its release. It centers on two main questions: the envisioned applications and the concerns related to Sora's integration. The analysis forecasts positive shifts in content creation, predicting that Sora will democratize video marketing and innovate game development by making video production more accessible and economical. Conversely, there are concerns about deepfakes and the potential for disinformation, underscoring the need for strategies to address disinformation and bias. This paper contributes to the Gen-AI discourse by fostering discussion on current and future capabilities, enriching the understanding of public expectations, and establishing a temporal benchmark for user anticipation. This research underscores the necessity for informed, ethical approaches to AI development and integration, ensuring that technological advancements align with societal values and user needs.\\n\\nPublished: 2024-05-30\\nTitle: Analysing the Public Discourse around OpenAI's Text-To-Video Model 'Sora' using Topic Modeling\\nAuthors: Vatsal Vinay Parikh\\nSummary: The recent introduction of OpenAI's text-to-video model Sora has sparked widespread public discourse across online communities. This study aims to uncover the dominant themes and narratives surrounding Sora by conducting topic modeling analysis on a corpus of 1,827 Reddit comments from five relevant subreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT). The comments were collected over a two-month period following Sora's announcement in February 2024. After preprocessing the data, Latent Dirichlet Allocation (LDA) was employed to extract four key topics: 1) AI Impact and Trends in Sora Discussions, 2) Public Opinion an\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=arxiv.run(\"sora\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Search(query='gpt-4', id_list=[], max_results=5, sort_by=<SortCriterion.Relevance: 'relevance'>, sort_order=<SortOrder.Descending: 'descending'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "search=arxiv.Search(\n",
    "    query=\"gpt-4\",\n",
    "    max_results=5,\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.islice at 0x173d9dc6610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client=arxiv.Client()\n",
    "results=client.results(search)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/abs/2304.03277v1\n",
      "http://arxiv.org/abs/2303.13375v2\n",
      "http://arxiv.org/abs/2308.07921v1\n",
      "http://arxiv.org/abs/2311.15732v2\n",
      "http://arxiv.org/abs/2312.14302v2\n"
     ]
    }
   ],
   "source": [
    "papers=[]\n",
    "for item in results:\n",
    "    print(item) \n",
    "    papers.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Result(entry_id='http://arxiv.org/abs/2304.03277v1', updated=datetime.datetime(2023, 4, 6, 17, 58, 9, tzinfo=datetime.timezone.utc), published=datetime.datetime(2023, 4, 6, 17, 58, 9, tzinfo=datetime.timezone.utc), title='Instruction Tuning with GPT-4', authors=[arxiv.Result.Author('Baolin Peng'), arxiv.Result.Author('Chunyuan Li'), arxiv.Result.Author('Pengcheng He'), arxiv.Result.Author('Michel Galley'), arxiv.Result.Author('Jianfeng Gao')], summary='Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.', comment='8 pages. Work in progress. Project page: https://instruction-tuning-with-gpt-4.github.io', journal_ref=None, doi=None, primary_category='cs.CL', categories=['cs.CL', 'cs.AI'], links=[arxiv.Result.Link('https://arxiv.org/abs/2304.03277v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('https://arxiv.org/pdf/2304.03277v1', title='pdf', rel='related', content_type=None)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2023-09-22', 'Title': \"OpenAi's GPT4 as coding assistant\", 'Authors': 'Lefteris Moussiades, George Zografos', 'Summary': 'Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools.'}, page_content='OPENAI’S GPT4 AS CODING ASSISTANT\\nLefteris Moussiades\\nComputer Science Department\\nInternational Hellenic University\\nGreece, Kavala PA 65404\\nlmous@cs.ihu.gr\\nGeorge Zografos\\nComputer Science Department\\nInternational Hellenic University\\nGreece, Kavala PA 65404\\ngezozra@cs.ihu.gr\\nSeptember 25, 2023\\nABSTRACT\\nLately, Large Language Models have been widely used in code generation. GPT4 is considered the\\nmost potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4\\nas coding assistants. More specifically, we have constructed appropriate tests to check whether\\nthe two systems can a) answer typical questions that can arise during the code development, b)\\nproduce reliable code, and c) contribute to code debugging. The test results are impressive. The\\nperformance of GPT4 is outstanding and signals an increase in the productivity of programmers and\\nthe reorganization of software development procedures based on these new tools.\\n1\\nIntroduction\\nAmong other features, Large Language Models (LLM) can generate code in various programming languages [1].\\nRecently, many publications have recommended and evaluated LLMs specialized in code generation.\\nCodeBERT is a bimodal pre-trained model designed for programming and natural language tasks, like code search\\nand documentation generation. It’s developed using a Transformer-based architecture [2] and trained with a unique\\nobjective function to effectively use paired and unpaired data from programming and natural language sources [3].\\nCodex is a GPT language model fine-tuned on public GitHub code, and a version of it powers GitHub Copilot. When\\nevaluated on the HumanEval set, designed to gauge program synthesis from docstrings, Codex solves 28.8% of the tasks,\\noutperforming GPT-3 and GPT-J. The study also uncovers that multiple samplings from Codex enhance problem-solving\\nsuccess rates. Additionally, the paper discusses the challenges and broader implications of advanced code generation\\ntechnologies [4].\\nThe capabilities of large language models in synthesizing Python programs from natural language prompts using two\\nnew benchmarks, MBPP and MathQA-Python, are explored by [5]. The study reveals that as model size increases,\\nsynthesis performance also improves, with the largest models being able to correctly generate solutions to nearly 60%\\nof MBPP problems through few-shot learning. The models also benefit from human feedback, cutting error rates in half,\\nbut struggle to predict the outputs of the generated programs when provided with specific inputs.\\nStudy [6] introduces a novel approach to code completion using an \"external\" context, emulating human behaviour of\\nreferencing related code snippets. The proposed framework combines retrieval techniques with traditional language\\nmodels to better predict code, factoring in direct copying and semantically similar code references. When tested on\\nPython and Java, this method achieves state-of-the-art performance on the CodeXGLUE benchmark.\\nPaper [7] explores LLMs trained on unlabeled code corpora for code generation. It introduces CERT, a two-step method\\nthat creates a basic code outline and then fills in the details. The study also presents two new benchmarks, PandasEval\\nand NumpyEval, for evaluating library-oriented code generation.\\nPanGu-Coder is a pre-trained language model built on the PanGu-Alpha architecture designed to generate code from\\nnatural language descriptions. The model is trained using a two-stage strategy, starting with raw programming data,\\nfollowed by task-focused training using Causal and Masked Language Modelling objectives [8]\\narXiv:2309.12732v1  [cs.AI]  22 Sep 2023\\nLi et al. introduced AlphaCode, a deep-learning model built with self-supervised learning and an encoder-decoder\\ntransformer, which approximates human-level performance in computer programming competitions on the Codeforces\\nplatform. Authors argue that this advancement could significantly boost programmers’ productivity and reshape\\nprogramming culture, where humans primarily define problems and machine learning handles code generation and\\nexecution [9].\\nCODEGEN is a family of large language models trained on natural language and programming data to advance program\\nsynthesis. The study also explores a multi-step approach to program synthesis, revealing improved performance\\nwhen tasks are broken down into multiple prompts, and introduces an open benchmark, the Multi-Turn Programming\\nBenchmark (MTPB), for this purpose [10].\\nPaper [11] investigates the impact of LLMs, like OpenAI Codex, on developers’ code security. Through a user study\\ninvolving 58 student programmers, the research examines the code’s security when implementing a specific C-based\\ntask with the assistance of LLMs. The findings suggest that using LLMs does not substantially increase the risk of\\nintroducing critical security vulnerabilities in such coding tasks.\\nRepoCoder [12] is a framework designed for repository-level code completion that efficiently leverages information\\nscattered across different files in a repository. RepoCoder uses a combination of a similarity-based retriever and a\\npre-trained code language model, along with an innovative iterative retrieval-generation approach, to improve code\\ncompletion at various levels of granularity. RepoCoder has been tested on a new benchmark called RepoEval.\\nPaper [13] thoroughly surveys 27 large language models geared explicitly towards the NL2Code task, which involves\\ngenerating code from natural language descriptions. The study evaluates these models using the HumanEval benchmark\\nand derives that success in this domain hinges on \"Large Size, Premium Data, Expert Tuning\". The authors also\\nintroduce a dedicated website to monitor ongoing advancements and discuss the gap between model performance and\\nhuman capabilities in the NL2Code realm.\\nThe BigCode community has unveiled StarCoder and StarCoderBase, advanced Large Language Models designed for\\ncode generation and infilling, with StarCoderBase trained on a vast dataset called The Stack and StarCoder being a\\nfine-tuned version for Python [14].\\nWizardCoder is a model that empowers Code Large Language Models (Code LLMs) with complex instruction fine-\\ntuning by adapting the Evol-Instruct method to the domain of code. It has been introduced in a paper [15] and has\\ndemonstrated exceptional performance in code-related tasks.\\nStudy [16] investigates the use of large language models (LLMs) to aid in deductive coding, a method in qualitative\\nanalysis where data is labelled based on predetermined codebooks. The approach reached satisfactory alignment with\\nexpert-labelled outcomes by integrating GPT-3 with expert-created codebooks for a specific task related to coding\\ncuriosity-driven questions. The paper highlights the potential and challenges of employing LLMs in qualitative data\\ncoding and broader applications.\\nOne result of all this development is the addition of intelligent assistants to many well-known IDEs. For example, Visual\\nStudio Code is supported by IntelliCode, PyCharm by Code With Me, Eclipse by Code Recommenders, NetBeans by\\nDeep Learning, IntelliJ IDEA by Code With Me, and Xcode by SourceKit-LSP [17].\\nIn March 2023, Openai published the GPT-4 system card, which [18] analyzes the capabilities of GPT-4, including\\ncode generation. However, to date, we have not found any publication evaluating the coding capabilities of GPT-4. This\\npaper evaluates GPT-4 and GPT-3.5 as coding assistants.\\n2\\nMethodology\\nWe consider three tasks for which a coding assistant should be helpful: Code development, Code Debugging, and\\nanswering questions related to code. Code development and Code debugging are self-explanatory concepts. The human\\nprogrammer often has questions during code writing, such as details on the syntax of a command. For this reason, we\\ncheck that GPT-3.5 and 4 can answer questions about the code satisfactorily.\\nThere are many source code datasets, several mentioned in the introduction. However, these are geared to check LLMs’\\ncode production specifically. In addition, problems of a prototypical nature often arise in the production environment.\\nAlthough we do not know exactly which data sets GPT-3.5 and 4 are trained on, it is reasonable to assume that they\\nare trained on public data sets whose purpose is to evaluate LLMs’ coding capabilities. For the reasons above, our\\ntests do not rely on such data sets. Instead, we have carefully constructed 3 test suites: one for testing code generation\\ncapabilities, one for testing debugging capabilities, and one for answering questions. The tests were designed to limit\\nthe chances that GPT3.5 and 4 were trained on exactly those requested codes. The tests were submitted through the\\n2\\nweb interface of GPT3.5 and 4. The prompt engineering of the tests follows the GPT best practices of Openai [19]. The\\nresults were evaluated based on an expert human reviewer or compared to another reliable source. As the tests are about\\nchecking different capabilities, more details about the test configuration and the evaluation of the results are given with\\nthe description of each test. Java was used as the programming language. All code and other answers generated by\\nGPT3.5 and 4 is on GitHub [19].\\n3\\nAnswering questions\\nIn this task, we test the assistants to see if they can answer questions that often arise for developers when developing\\ncode. For this purpose, we constructed three questions of relative difficulty. We list the relevant prompts and then\\nevaluate the assistants’ answers.\\n• Question 1 (Prompt):\\nDoes Java support passing a function as an argument to a function? What is the syntax?\\n• Question 2 (Prompt):\\nConsider the code\\nSystem.out.print(s==s1+\" \"+s.equals(s1));\\nI expected it to display two boolean values, but it displays only one. Explain why?\\n• Question 3 (Prompt):\\nNon-abstract methods have an implementation. The same applies to the default methods.\\nNon-abstract methods are inherited and can be overwritten. The same applies to default methods.\\nWhat is the difference between default methods and non-abstract ones? Answer briefly.\\nResponse\\nGPT3.5 and 4 responses were evaluated by a human expert and found to answer all three questions satisfactorily.\\nResponses can be found on Github [20].\\n4\\nCode Development Assistance\\nFor code development, we constructed two tests. The first asks for developing a power function, and the second for\\nimplementing a tic-tac-toe application with predetermined classes.\\n4.1\\nPower function (PF)\\nIn this task, we asked GPT3.5 and 4 to implement a function that calculates the power of a real number raised to an\\ninteger exponent. Although the task seems simple at first glance, it is demanding when high calculation precision is\\nrequired. The difficulty arises from the approximate nature of real numbers. Due to the approximate nature of real\\nnumbers, the results of operations lack precision. When there are many intermediate operations, the deviations from\\neach operation accumulate, and the final result may present a significant deviation. So, this is a complex implementation\\nwhen precision is required in the calculations. Moreover, it is a feature, not a concern for application developers, as all\\nlanguages provide a ready-made power function. Besides, after an exhaustive search on the web, we could not find a\\nhigh-precision implementation.\\nEvaluation\\nThe generated functions were compared with the Java Math.pow function. The Math.pow() function is implemented\\nin Java as a native method, which means that it is implemented in the underlying platform’s native code. The\\nimplementation of Math.pow() varies depending on the platform and the underlying hardware architecture. The\\nalgorithm is optimized for speed and accuracy and is presumed to be relatively accurate. The results were checked\\nbased on the following procedure.\\nLet GPT4.pow be the function produced by GPT4 and r(f,b,e) the result of the function f with base b and exponent\\ne. For each b from 500 to 1000 with step 1 and each e from 0 to 9 with step 1, the values r(GPT4.pow,b,e) and\\nr(Math.pow,b,e) are calculated. Assume that for each pair of these values, even one is non-infinite, and they differ from\\neach other by more than 4.9E-324 (the smallest real value represented by Java double type). In that case, the absolute\\nvalue of their difference is added to an appropriate adder. Then, the adder is divided by the number of terms in the sum\\nand, thus, the average deviation of the GPT4.pow results from the Math.pow results are calculated. The same process is\\n3\\nrepeated to compare GPT3.5.pow to Math.pow. The whole process is repeated for exponents from -1 to -9.\\nPF Prompt #1\\nDevelop a Java function that calculates the power of a real number raised to an integer exponent.\\nSpecifications:\\n1. Interface: public static double pow(double b, int e)\\n2. Don’t use Math.pow or BigDecimal.pow\\n3. Achieve the maximum possible precision\\nResponse\\nBoth systems responded by providing a satisfactory implementation based on the exponentiation by squaring algorithm.\\nThe algorithm has time complexity O(log n), where n is the exponent. The implementations are almost identical, with\\nonly two minor differences:\\n• GPT4 checks if the exponent is odd by performing a bitwise and with 1 ((e&1) == 1) while GPT3.5 performs\\nan integer division remainder calculation (e%2 == 1)\\n• GPT4 performs a right shift by 1 to divide the exponent by 2 (e >>= 1), whereas GPT3.5 performs integer\\ndivision (e/ = 2) for the same purpose.\\nThe algorithms presented the same average deviation with respect to Math.pow, which was 2.356527240763158E10 for\\npositive exponents and 1.7112490986192953E-22 for negative exponents.\\nPF Prompt #2\\nCan you improve the precision of your function? I checked it against Math.pow and found significant discrepancies.\\nExamples:\\nbase = 502, exponent= 9, GPT.pow = 2.0245730632526733E24, Math.pow = 2.024573063252673E24, diference =\\n2.68435456E8\\nbase = 504, exponent = 9, GPT.pow = 2.098335016107156E24, Math.pow = 2.0983350161071556E24, diference =\\n2.68435456E8\\nResponse\\nGPT3.5 responded with a function that implements the Taylor series expansion [21] algorithm, which increases time\\ncomplexity to O(e2). GPT4 again used exponentiation by squaring but used the BigDecimal class [22], recommended\\nfor cases requiring precision in calculations.\\nThe mean deviation of GPT3.5 worsened to 2.2292150579952536E25 for positive exponents and 1.0012331308931004\\nfor negative ones.\\nThe mean deviation of GPT4 improved to 2.3037066373333335E9 for positive exponents and 2.1726446876877912E-2\\nfor negative ones.\\n4.2\\nTic-Tac-Toe application (TTT)\\nIn this task, we asked GPT to develop a tic-tac-toe application following especial specifications. We set certain\\nspecifications to minimize the chance that a tic-tac-toe app would be found ready-made and delivered intact.\\nTTT Prompt #1\\nDevelop a command-line tic-tac-toe application consisting of the following classes:\\nPlayer, Board, LivePlayer, RBPlayer, and Game.\\n• Player: Is an Abstract class containing , final char id, abstract method Board move(Board board)\\n4\\n• Class Board: Represents the game board. It contains the following public function members:\\nvoid displayBoard(): It displays the game board on its current status\\nchar win(): It returns the winner’s id. If there is no winner, it returns a white character.\\n• Class LivePlayer: Represents a human player. It is a concrete class implementation inherited from Player.\\n• Class RBPlayer: Represents an artificial Rule-based Player. It is based on the following rules:\\nA. If there is a movement to win, select it.\\nB. If the opponent has a movement to win, select it to block the opponent from winning.\\n• Game: Uses the above-described classes to implement a tic-tac-toe game.\\nResponse\\nGPT4 respond with a fully functional application that meets all our requirements. The code quality is good, including a\\nwarning that the used Board object could have been declared final.\\nGPT3.5 responded with code that contained compile time errors. We performed the following communication to\\ninvestigate its ability to produce correct code.\\nTTT Prompt #1.1\\nYour code compiles with errors. Examples:\\n• error: cells has private access in Board\\nboard.cells[i][j] = id;\\n• error: cannot assign a value to final variable board\\nboard = currentPlayer.move(board);\\nRewrite code to avoid compile-time errors.\\nGPT3.5 replied with code containing logical errors. We prompt it as follows:\\nTTT Prompt #1.2\\nYour code has logical errors. Here is the output of your code after two movements of each player\\nPlayer X, enter your move (row [0-2] and column [0-2]): 1 1\\n————-\\n|\\n|\\n|\\n|\\n————-\\n|\\n| X |\\n|\\n————-\\n|\\n|\\n|\\n|\\n————-\\n————-\\n| O |\\n|\\n|\\n————-\\n|\\n|\\n|\\n|\\n————-\\n|\\n|\\n|\\n|\\n————-\\nAfter the second fix, in the third version of the application, GPT3.5 responded with functional code.\\nGPT4 respond with a fully functional application that meets all our requirements. The code quality is good, including a\\nwarning that the used Board object could have been declared final.\\nNext, we requested a new class representing an artificial player based on the minimax [23] algorithm. The minimax\\nimplements a perfect player, i.e., a player who never loses. Therefore, the worst possible outcome minimax may give is\\n5\\na draw.\\nTTT Prompt #2\\nCan you add the class MinimaxPlayer representing an artificial player based on the well-known minimax algorithm?\\nResponse\\nGPT4 responded with a fully functional minimax player. GPT3.5 replayed with an erroneous version of a minimax\\nplayer. A communication ensued in which we attempted to inform GPT3.5 of its errors, but it failed to present a\\nsatisfactory solution. Finally, we prompt GPT3.5 as follows:\\nTTT Prompt #2.1\\nNo improvement. It’s still straightforward for anyone to win your MinimaxPlayer. I’m giving you the game board if it\\ncan help you. Please don’t give me the same wrong algorithm again. If you can’t do better, just let me know.\\nPlayer X, enter your move (row [0-2] and column [0-2]): 2 0\\n————-\\n| O | O | X |\\n————-\\n| O | X |\\n|\\n————-\\n| X |\\n|\\n|\\n————-\\nPlayer X wins!\\nHere, GPT3.5 explained the difficulties of implementing the algorithm and suggested that we study the matter more or\\nlook for a ready-made solution on GitHub.\\n5\\nDebugging Assistance (DA)\\nTo test the debugging capabilities, we designed two tests. One includes code that throws an exception, and the other\\nincludes code containing a logic error.\\n5.1\\nException (E)\\nIn this task, we provided a code that crashes with IndexOutOfBoundsException and asked GPT3.5 and 4 to explain the\\nproblem and fix the code.\\nDA-E Prompt #1\\nThe Code below fails with IndexOutOfBoundsException.\\nimport java.util.ArrayList;\\nimport java.util.List;\\npublic class Debug2 {\\nstatic ArrayList<String> l=new ArrayList<>();\\nstatic void load() {\\nl.add(\"Green\");\\nl.add(\"Black\");\\nl.add(\"Blue\");\\nl.add(\"White\");\\nl.add(\"Pink\");\\nl.add(\"Black\");\\n}\\nstatic void delAll(List<String> l, String target) {\\n6\\nint size=l.size();\\nfor (int i=0; i<size; i++)\\nif (target.equals(l.get(i))) {\\nl.remove(i);\\n}\\n}\\npublic static void main(String[] args) {\\nload();\\ndelAll(l,\"Black\");\\n}\\n}\\nExplain the error and correct the code.\\nExplanation of the error\\nFirst, the exception is raised in the delAll function, which is responsible for deleting all the target elements from the\\nlist l. The function stores the list size in the local variable size and then, in the iterative process, tries to delete every\\nelement equal to the target. However, after deleting the first element, the list size is reduced by 1. However, delAll tries\\nto access the list for its original size, which leads to the exception.\\nResponce\\nBoth assistants solved the problem successfully. While GPT3.5 proposed a solution based on an Iterator, GPT4 proposed\\ntwo alternatives. In the first solution, the for control expression replaces the size variable with the function that returns\\nthe list size (l.size()); inside the for, decrements i by one each time it deletes an element. The second solution traverses\\nthe list from the end (l.size()-1) to the beginning, thus ensuring no IndexOutOfBoundsException issue.\\n5.2\\nLogical Error (LE)\\nDA-LE Prompt #1\\nThe code below contains logical errors.\\nExpected Output: [1, 2, 3, 4, 0, 5, 6]\\nActual Output: [1, 2, 3, 4, 5, 6, 0, 0, 0, 0]\\nExplain the errors and correct the code.\\n// Code containing logical error\\nimport java.util.Arrays;\\npublic class Debugging {\\nstatic int[] resize(int[] input, int newSize) {\\nreturn Arrays.copyOf(input, newSize < input.length ? newSize : input.length);\\n}\\nstatic int add(int[] array, int data, int index) {\\nfor (int i = 0; i <= index; i++) {\\nif (array[i] == data) {\\nreturn index;\\n}\\n}\\narray[index++] = data;\\nreturn index;\\n}\\nstatic int[] generateSet(int... array) {\\nint[] set = new int[array.length];\\nint idx = 0;\\nfor (int element : array) {\\n7\\nidx = add(set, element, idx);\\n}\\nresize(set, idx);\\nreturn set;\\n}\\nstatic int[] concat(int[] array1, int[] array2) {\\nint[] rslt = new int[array1.length + array2.length];\\nSystem.arraycopy(array1, 0, rslt, 0, array1.length);\\nSystem.arraycopy(array2, 0, rslt, array1.length, array2.length);\\nreturn generateSet(rslt);\\n}\\npublic static void main(String[] args) {\\nint[] set1 = generateSet(1, 2, 3, 4, 0),\\nset2 = generateSet(0, 3, 4, 5, 6);\\nint[] union = concat(set1, set2);\\nSystem.out.println(Arrays.toString(union));\\n}\\n}\\nExplanation of the error\\nThere are two bugs in the code. The first one is found in generateSet, which calls the function resize but does not assign\\nthe array returned by resize to the set variable. Thus, the set retains its original size and data. So the fix needed here is\\nreturn resize(set, idx); instead of resize(set,idx); return set; The second error is within the add function, which iterates\\nwhile i<=index, whereas the correct condition is i<index.\\nResponse\\nFirst, GPT3.5 and GPT4 correctly explained the problems in the add and generateSet functions. In addition, they\\nidentified a resize problem when there is none. More specifically, GPT3.5 commented:\\n1. The resize method is not updating the size of the array correctly. It creates a new array of the specified size but\\ndoesn’t copy the elements from the original array.\\n2. Use Arrays.copyOf to create a new array of the desired size and copy the elements from the original array to\\nthe new one.\\nAnd GPT4 commented:\\n1. Resize method: In the current implementation, if newSize is larger than input.length, it would return an array\\nof the same size as input. This does not match the intended behavior of resizing the array to newSize.\\nThese comments are wrong.\\nHowever, the generated codes are functional as they correctly fix both add and generateSet, while the change they make\\nto resize does not affect the specific code. More specifically, both systems converted resize so that it does not support\\nreducing the size of the input table. Indeed, size reduction is not needed in this code. Of course, a resize that helps\\nreduce a table’s length (with possible data loss) might be helpful elsewhere.\\n6\\nConclusions\\nIn this work, we examined the potential of GPT3.5 and 4 as coding assistants for three distinct tasks: Answering\\nquestions and providing Development and Debugging assistance. In answering questions, both LLMs proved to be\\nefficient. In Development assistance, GPT4 proved superior to GPT3.5. Both in creating the pow function, it achieved a\\nsignificant improvement in accuracy, and in the requirements for the tic-tac-toe application, it immediately responded\\nwith complete success. Moreover, it added a player based on the Minimax algorithm with ease. This is a requirement,\\naccording to our estimation, that is far from easy to implement. GPT3.5 failed to meet this requirement. In testing the\\ndebugging capabilities, GPT3.5 and 4 responded promptly and successfully to exception and logical error investigations.\\nThese conclude that GPT4 can provide substantial and reliable help as a coding assistant for all three properties tested.\\nAs expected, GPT3.5 appeared inferior to GPT4, but its capabilities are still impressive. Recently, a heated debate has\\nbeen about whether artificial intelligence will replace human programmers. We believe the answer to this question is\\n8\\nimpossible, as no one can predict the future. However, currently, GPT4 can provide meaningful and reliable assistance\\nto coding and dramatically improve the productivity of human developers. Such a thing is sure to reorganize the\\nsoftware production processes and possibly will not leave the job market of programmers unaffected. Whether its effect\\nwill increase the amount of software produced or unemployment in the developer industry remains to be seen.\\nReferences\\n[1] A. Tamkin, M. Brundage, J. Clark, and D. Ganguli, “Understanding the Capabilities, Limitations, and Societal\\nImpact of Large Language Models,” 2021.\\n[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention\\nIs All You Need,” Aug. 2023. arXiv:1706.03762 [cs].\\n[3] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang, and M. Zhou,\\n“CodeBERT: A Pre-Trained Model for Programming and Natural Languages,” 2020.\\n[4] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman,\\nA. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov,\\nA. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis,\\nE. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji,\\nS. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight,\\nM. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and\\nW. Zaremba, “Evaluating Large Language Models Trained on Code,” 2021.\\n[5] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, and\\nC. Sutton, “Program Synthesis with Large Language Models,” 2021.\\n[6] S. Lu, N. Duan, H. Han, D. Guo, S.-w. Hwang, and A. Svyatkovskiy, “ReACC: A Retrieval-Augmented Code\\nCompletion Framework,” 2022.\\n[7] D. Zan, B. Chen, D. Yang, Z. Lin, M. Kim, B. Guan, Y. Wang, W. Chen, and J.-G. Lou, “CERT: Continual\\nPre-Training on Sketches for Library-Oriented Code Generation,” 2022.\\n[8] F. Christopoulou, G. Lampouras, M. Gritta, G. Zhang, Y. Guo, Z. Li, Q. Zhang, M. Xiao, B. Shen, L. Li, H. Yu,\\nL. Yan, P. Zhou, X. Wang, Y. Ma, I. Iacobacci, Y. Wang, G. Liang, J. Wei, X. Jiang, Q. Wang, and Q. Liu,\\n“PanGu-Coder: Program Synthesis with Function-Level Language Modeling,” 2022.\\n[9] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago,\\nT. Hubert, P. Choy, C. De Masson d’Autume, I. Babuschkin, X. Chen, P.-S. Huang, J. Welbl, S. Gowal,\\nA. Cherepanov, J. Molloy, D. J. Mankowitz, E. Sutherland Robson, P. Kohli, N. De Freitas, K. Kavukcuoglu, and\\nO. Vinyals, “Competition-level code generation with AlphaCode,” Science, vol. 378, pp. 1092–1097, Dec. 2022.\\n[10] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong, “CodeGen: An Open\\nLarge Language Model for Code with Multi-Turn Program Synthesis,” 2022.\\n[11] G. Sandoval, H. Pearce, T. Nys, R. Karri, S. Garg, and B. Dolan-Gavitt, “Lost at C: A User Study on the Security\\nImplications of Large Language Model Code Assistants,” 2022.\\n[12] F. Zhang, B. Chen, Y. Zhang, J. Liu, D. Zan, Y. Mao, J.-G. Lou, and W. Chen, “RepoCoder: Repository-Level\\nCode Completion Through Iterative Retrieval and Generation,” 2023.\\n[13] D. Zan, B. Chen, F. Zhang, D. Lu, B. Wu, B. Guan, Y. Wang, and J.-G. Lou, “Large Language Models Meet\\nNL2Code: A Survey,” 2022.\\n[14] R. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim, Q. Liu,\\nE. Zheltonozhskii, T. Y. Zhuo, T. Wang, O. Dehaene, M. Davaadorj, J. Lamy-Poirier, J. Monteiro, O. Shliazhko,\\nN. Gontier, N. Meade, A. Zebaze, M.-H. Yee, L. K. Umapathi, J. Zhu, B. Lipkin, M. Oblokulov, Z. Wang,\\nR. Murthy, J. Stillerman, S. S. Patel, D. Abulkhanov, M. Zocca, M. Dey, Z. Zhang, N. Fahmy, U. Bhattacharyya,\\nW. Yu, S. Singh, S. Luccioni, P. Villegas, M. Kunakov, F. Zhdanov, M. Romero, T. Lee, N. Timor, J. Ding,\\nC. Schlesinger, H. Schoelkopf, J. Ebert, T. Dao, M. Mishra, A. Gu, J. Robinson, C. J. Anderson, B. Dolan-Gavitt,\\nD. Contractor, S. Reddy, D. Fried, D. Bahdanau, Y. Jernite, C. M. Ferrandis, S. Hughes, T. Wolf, A. Guha, L. von\\nWerra, and H. de Vries, “StarCoder: may the source be with you!,” 2023.\\n[15] Z. Luo, C. Xu, P. Zhao, Q. Sun, X. Geng, W. Hu, C. Tao, J. Ma, Q. Lin, and D. Jiang, “WizardCoder: Empowering\\nCode Large Language Models with Evol-Instruct,” 2023.\\n[16] Z. Xiao, X. Yuan, Q. V. Liao, R. Abdelghani, and P.-Y. Oudeyer, “Supporting Qualitative Analysis with Large\\nLanguage Models: Combining Codebook with GPT-3 for Deductive Coding,” in 28th International Conference\\non Intelligent User Interfaces, (Sydney NSW Australia), pp. 75–78, ACM, Mar. 2023.\\n9\\n[17] F.\\nOkeke,\\n“The\\n12\\nbest\\nIDEs\\nfor\\nprogramming.”\\nhttps://www.techrepublic.com/article/\\nbest-ide-software/, July 2022. [Accessed 14-09-2023].\\n[18] “GPT-4 System Card | Data Science Association.” http://www.datascienceassn.org/content/\\ngpt-4-system-card. [Accessed 14-09-2023].\\n[19] “OpenAI Platform.” https://platform.openai.com/docs/guides/gpt-best-practices. [Accessed 14-\\n09-2023].\\n[20] “GitHub\\n-\\nlmous/openai-gpt4-coding-assistantt\\n—\\ngithub.com.”\\nhttps://github.com/lmous/\\nopenai-gpt4-coding-assistant. [Accessed 15-09-2023].\\n[21] “Taylor Series – from Wolfram MathWorld — mathworld.wolfram.com.” https://mathworld.wolfram.com/\\nTaylorSeries.html. [Accessed 15-09-2023].\\n[22] “BigDecimal (Java Platform SE 8 ).” https://docs.oracle.com/javase/8/docs/api/java/math/\\nBigDecimal.html. [Accessed 15-09-2023].\\n[23] J. von Neumann, O. Morgenstern, and A. Rubinstein, Theory of Games and Economic Behavior (60th Anniversary\\nCommemorative Edition). Princeton University Press, 1944.\\n10\\n')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs=ArxivLoader(query=\"2309.12732v1\",load_max_docs=2).load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\"{article}\\n\\n\\n请使用中文详细讲解上面这篇文章内容，并将核心的要点提炼出来\")\n",
    "\n",
    "chain=prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这篇文章题为《OpenAI的GPT4作为编码助手》，作者是Lefteris Moussiades和George Zografos，来自希腊国际希腊大学计算机科学系。文章发表于2023年9月25日，主要评估了GPT-3.5和GPT-4作为编程助手的性能，涵盖三个核心任务：**回答问题**、**代码开发**和**代码调试**。\n",
      "\n",
      "---\n",
      "\n",
      "## 一、文章核心内容讲解\n",
      "\n",
      "### 1. **研究背景与动机**\n",
      "- **大型语言模型（LLM）** 在代码生成领域已被广泛应用，如CodeBERT、Codex、AlphaCode等。\n",
      "- GPT-4被认为是当前最强大的LLM之一，但尚未有公开研究系统评估其编码能力。\n",
      "- 本文旨在填补这一空白，通过自定义测试集（非公开基准数据集）评估GPT-3.5和GPT-4在真实编程场景中的表现。\n",
      "\n",
      "### 2. **研究方法**\n",
      "- 设计了三个测试套件：\n",
      "  - **回答问题**：模拟开发者常见的语法、语义疑问。\n",
      "  - **代码开发**：要求生成特定功能的代码（如高精度幂函数、井字棋游戏）。\n",
      "  - **代码调试**：提供有异常或逻辑错误的代码，要求解释并修复。\n",
      "- 使用Java作为编程语言，通过OpenAI的Web界面进行交互，遵循最佳提示工程实践。\n",
      "- 结果由人类专家评估或与可靠来源（如Java标准库函数）对比。\n",
      "\n",
      "### 3. **回答问题能力测试**\n",
      "- 提出了三个具有挑战性的问题：\n",
      "  1. Java是否支持将函数作为参数传递？语法是什么？\n",
      "  2. 解释一段代码为何只输出一个布尔值而非两个。\n",
      "  3. 简要说明Java中“默认方法”与“非抽象方法”的区别。\n",
      "- **结果**：GPT-3.5和GPT-4均能正确回答所有问题，表现令人满意。\n",
      "\n",
      "### 4. **代码开发能力测试**\n",
      "#### a) **幂函数实现（PF）**\n",
      "- **要求**：实现高精度计算 `pow(double b, int e)`，不使用`Math.pow`或`BigDecimal.pow`。\n",
      "- **第一轮**：两者均使用“平方取幂”算法实现，但GPT-4使用位运算优化，GPT-3.5使用算术运算。\n",
      "- **精度对比**：与`Math.pow`对比，两者平均偏差相近。\n",
      "- **第二轮**：要求提升精度。\n",
      "  - GPT-3.5改用泰勒级数展开，但精度反而下降。\n",
      "  - GPT-4改用`BigDecimal`类，精度显著提升。\n",
      "- **结论**：GPT-4在精度优化方面表现更优。\n",
      "\n",
      "#### b) **井字棋游戏实现（TTT）**\n",
      "- **要求**：按照特定类结构（Player、Board、LivePlayer、RBPlayer、Game）实现命令行井字棋游戏。\n",
      "- **第一轮**：\n",
      "  - GPT-4直接生成完整、可运行且符合要求的代码。\n",
      "  - GPT-3.5的代码存在编译错误和逻辑错误，需多次提示修正。\n",
      "- **第二轮**：要求添加基于Minimax算法的完美AI玩家。\n",
      "  - GPT-4成功实现功能完整的Minimax玩家。\n",
      "  - GPT-3.5无法正确实现，最终承认困难并建议参考外部资源。\n",
      "\n",
      "### 5. **代码调试能力测试**\n",
      "#### a) **异常调试（E）**\n",
      "- 提供一段因列表删除元素后索引越界而抛出异常的代码。\n",
      "- **结果**：两者均能正确解释错误原因，并提供修复方案（GPT-4提供两种方案）。\n",
      "\n",
      "#### b) **逻辑错误调试（LE）**\n",
      "- 提供一段输出不符合预期的代码（涉及数组操作）。\n",
      "- **结果**：\n",
      "  - 两者都正确识别了主要逻辑错误（循环条件错误、未接收返回值）。\n",
      "  - 两者都误判了`resize`函数的问题（实际上无需修改），但生成的修复代码仍能正确运行。\n",
      "\n",
      "### 6. **结论**\n",
      "- **GPT-4** 在所有任务中表现优异，尤其在代码开发（高精度计算、复杂算法实现）方面明显优于GPT-3.5。\n",
      "- **GPT-3.5** 虽然稍逊，但仍能提供有价值的帮助。\n",
      "- **整体意义**：GPT-4能够显著提升程序员的生产力，并可能重组软件开发流程。目前尚不能断言AI将完全取代人类程序员，但其作为辅助工具的影响已不可忽视。\n",
      "\n",
      "---\n",
      "\n",
      "## 二、核心要点提炼\n",
      "\n",
      "1. **评估维度全面**：覆盖了编程助手三大核心场景——答疑、开发、调试。\n",
      "2. **GPT-4优势明显**：\n",
      "   - 代码生成质量高，一次通过率更高。\n",
      "   - 能实现复杂算法（如Minimax），且代码结构清晰。\n",
      "   - 在精度要求高的任务中优化能力更强。\n",
      "3. **GPT-3.5仍有价值**：虽需更多迭代修正，但基础能力仍可靠。\n",
      "4. **方法科学**：采用自定义测试集，避免数据泄露问题，更贴近真实开发场景。\n",
      "5. **现实意义**：\n",
      "   - AI编程助手已能实质性提升开发效率。\n",
      "   - 可能推动软件开发流程变革，但人类程序员的核心作用（问题定义、架构设计等）依然关键。\n",
      "6. **未来展望**：AI是否会取代程序员尚无定论，但其作为生产力工具的整合已不可避免。\n",
      "\n",
      "---\n",
      "\n",
      "## 三、启示与思考\n",
      "\n",
      "- **对开发者**：应学习如何有效利用AI编程助手（如提示工程、结果验证），将其融入工作流。\n",
      "- **对教育界**：编程教学可能需要调整，更注重问题分解、算法设计等高阶能力，而非单纯语法记忆。\n",
      "- **对行业**：企业需重新规划开发流程，可能减少基础编码需求，增加对AI工具管理和结果审核的角色。\n",
      "\n",
      "这篇文章通过严谨的测试设计，清晰展示了GPT-4作为编程助手的强大能力，为后续研究和实践应用提供了重要参考。"
     ]
    }
   ],
   "source": [
    "for chunk in chain.invoke({\"article\":docs[0].page_content}):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
