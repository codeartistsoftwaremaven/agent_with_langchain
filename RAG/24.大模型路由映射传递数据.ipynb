{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough\n",
    " \n",
    "runnable=RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    extra=RunnablePassthrough().assign(mult=lambda x:x[\"num\"]*3),\n",
    "    modified=lambda x:x[\"num\"]+1\n",
    " )\n",
    " \n",
    "runnable.invoke({\"num\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行自定义函数\n",
    "可以在管道中使用任意函数，这些函数必须是单个输入，如果有一个接受多个参数的函数，则应该编写一个包装函数，将其转换为单个输入函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI,ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(\n",
    "  model=\"qwen2.5-coder-1.5b-instruct\",\n",
    "  openai_api_key=\"EMPTY\",\n",
    "  base_url=\"http://127.0.0.1:1234/v1\",\n",
    "  temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import  itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "  \n",
    "def _multiple_length_function(text1,text2):\n",
    "    return len(text1)*len(text2)\n",
    "  \n",
    "def multi_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"],_dict[\"text2\"])\n",
    "  \n",
    "prompt=ChatPromptTemplate.from_template(\"what is {a}+{b}\")\n",
    "\n",
    "chain1=prompt | model\n",
    "\n",
    "chain=(\n",
    "    {\n",
    "        \"a\":itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        \"b\":{\"text1\":itemgetter(\"foo\"),\"text2\":itemgetter(\"bar\")} | RunnableLambda(multi_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sum of 3 and 9 is 12.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 25, 'total_tokens': 38, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen2.5-coder-1.5b-instruct', 'system_fingerprint': 'qwen2.5-coder-1.5b-instruct', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb9c65c1-4eb1-433d-898d-fc39176988b8-0', usage_metadata={'input_tokens': 25, 'output_tokens': 13, 'total_tokens': 38, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"foo\":\"bar\",\"bar\":\"gah\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\n",
    "  \"\"\"鉴于下面的用户问题，将其分类为'Langchain','OpenAI'或'其他'。\n",
    "  \n",
    "  不要用超过一个字来回应。\n",
    "  \n",
    "  <question>\n",
    "  {question}\n",
    "  </question>\n",
    "  \n",
    "  分类：\"\"\"\n",
    ")\n",
    "\n",
    "chain=(\n",
    "    prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\":\"我想知道Langchain的文档\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchainPrompt = PromptTemplate.from_template(\n",
    "    \"\"\"您是 langchain 方面的专家。\n",
    "回答问题时始终以“正如老陈告诉我的那样”开头。\n",
    "回答以下问题：\n",
    "\n",
    "问题：{question}\n",
    "回答：\"\"\"\n",
    ")\n",
    "langchain_chain = langchainPrompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAIPrompt = PromptTemplate.from_template(\n",
    "    \"\"\"您是 OpenAI 方面的专家。\n",
    "回答问题时始终以“正如奥特曼告诉我的那样”开头。\n",
    "回答以下问题：\n",
    "\n",
    "问题：{question}\n",
    "回答：\"\"\"\n",
    ")\n",
    "OpenAI_chain = OpenAIPrompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalPrompt = PromptTemplate.from_template(\n",
    "    \"\"\"回答以下问题：\n",
    "\n",
    "问题：{question}\n",
    "回答：\"\"\"\n",
    ")\n",
    "general_chain=generalPrompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"OpenAI\" in info[\"topic\"]:\n",
    "        return OpenAI_chain\n",
    "    elif \"Langchain\" in info[\"topic\"]:\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain={\"topic\":chain,\"question\": lambda x: x[\"question\"]} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='正如老陈告诉我那样，Langchain 的文档是非常详细的。你可以通过官方网站或 GitHub 上的官方仓库找到最新的文档和教程。此外，社区和论坛上也有大量的资源可以帮助你学习和使用 Langchain。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 58, 'total_tokens': 103, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen2.5-coder-1.5b-instruct', 'system_fingerprint': 'qwen2.5-coder-1.5b-instruct', 'finish_reason': 'stop', 'logprobs': None}, id='run-213ffe72-09d5-496f-ad73-fe95e060869a-0', usage_metadata={'input_tokens': 58, 'output_tokens': 45, 'total_tokens': 103, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"Langchain的文档是怎么样的？\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
